---
title: "Sun & Breheny (2019) webgazer replication"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

This study is a replication of Sun & Breheny (2019) with the web-based eye-tracking paradigm using the javascript webgazer library.

[Here](https://madiganbrodsky.github.io/eyetracking_replication/experiments/SunBreheny_webgazer/pilot/list1)'s the experiment we're analyzing.

```{r, message=F, warning=F}
library(tidyverse)
library(lme4)
library(ggplot2)
library("readxl")

# load helper scripts
source("helpers.R")

# load target word onsets
audio_info = read_excel("../data/audiotimes.xlsx")

# set color-blind-friendly color palette
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73")

# load data 
d = read.csv('../data/sunbreheny_webgazer_pilot2-merged.csv') %>%
  select(-location1,-location2,-location3,-location4,-location5,-location6,-location7,-location8,-location9,-location10,-target_figure,-target_object,-target_num_object,-error) %>% 
  filter(trial_type=="Exp") %>%
  mutate(target_location = ifelse((target1==7 | target2==7),"topleft",ifelse((target1==8 | target2==8),"bottomleft",ifelse((target1==9 | target2==9),"topright",ifelse((target1==10 | target2==10),"bottomright",NA))))) %>%
  mutate(competitor_location = ifelse((competitor1==7 | competitor2==7),"topleft",ifelse((competitor1==8 | competitor2==8),"bottomleft",ifelse((competitor1==9 | competitor2==9),"topright",ifelse((competitor1==10 | competitor2==10),"bottomright", NA))))) %>%
  left_join(audio_info,by=c("audio" = "Prime")) %>%
  filter(str_detect(proliferate.condition,"condition")) #only condition, condition1 and condition2 are in the final format (rest were previous pilots!!!)

# formatting
d$webgazer_time = gsub("\\[","",d$webgazer_time)
d$webgazer_time= gsub("\\]","",d$webgazer_time)
d$x = gsub("\\[","",d$x)
d$x = gsub("\\]","",d$x)
d$y = gsub("\\[","",d$y)
d$y = gsub("\\]","",d$y)
```


Exclude trials with wrong selections and plot subject information.
```{r,message=F,warning=F}
d = d %>% 
  mutate(selection_correct = ifelse(as.character(response) == as.character(target1),1, ifelse(as.character(response) == as.character(target2),1,0)),language = tolower(subject_information.language))

table(d$selection_correct)

d = d %>% 
  filter(selection_correct==1)

participants = d %>% 
  select(workerid,subject_information.accuracy,subject_information.age,subject_information.camblock,subject_information.comments, subject_information.eyesight, subject_information.eyesight_task, subject_information.gender, subject_information.headphones, language, subject_information.previous_accuracy_attempts, subject_information.time_in_minutes) %>% 
  unique()

# number of unique participants:
nrow(participants) 

# distribution of participant gender
table(participants$subject_information.gender)

# distribution of completion times
summary(participants$subject_information.time_in_minutes)
ggplot(participants, aes(x=subject_information.time_in_minutes)) +
  geom_histogram()

# distribution of calibration accuracy
summary(participants$subject_information.accuracy)
ggplot(participants, aes(x=subject_information.accuracy)) +
  geom_histogram()

# distribution of ages
summary(participants$subject_information.age)
ggplot(participants, aes(x=subject_information.age)) +
  geom_histogram()

# eyesight information
ggplot(participants, aes(x=subject_information.eyesight,fill=subject_information.eyesight_task)) +
  geom_histogram(stat="count")

# distribution of camera views -- some people continued to see camera view even during experiment (bug we haven't figured out yet how to fix)
ggplot(participants, aes(x=subject_information.camblock,fill=subject_information.camblock)) +
  geom_histogram(stat="count")

# distribution of headphone use
ggplot(participants, aes(x=subject_information.headphones)) +
  geom_histogram(stat="count")

# distribution of native languages
ggplot(participants, aes(x=language)) +
  geom_histogram(stat="count") +
  theme(axis.text.x=element_text(angle=45, hjust=1,vjust=1))
```

Separate time and x/y coordinates into separate data points, one per row, and define regions of interest (ROIs).
```{r,message=F,warning=F}
# set width and height of ROIs
imgwidth = 107 + 110 # boy/girl + objects
imgheight = 200 # boy/girl (taller than objects)

center_imgwidth = 220 # objects
center_imgheight = 110 # objects

scene_width = 1280 # everything takes place in a central 'scene' of  1280 x 750 pixels 
scene_height = 750 

dd = d %>%
  separate_rows(webgazer_time,x,y,convert=TRUE, sep=",") %>% 
  mutate(x_center = (system.windowW/2), y_center = (system.windowH/2),
           AOI_topleft_x_min = x_center - (scene_width/2),
           AOI_topleft_x_max = x_center - (scene_width/2) + imgwidth,
           AOI_topleft_y_min = y_center + (scene_height/2) - imgheight,
           AOI_topleft_y_max = y_center + (scene_height/2),
         
           AOI_bottomleft_x_min = x_center - (scene_width/2),
           AOI_bottomleft_x_max = x_center - (scene_width/2) + imgwidth,
           AOI_bottomleft_y_min = y_center - (scene_height/2),
           AOI_bottomleft_y_max = y_center - (scene_height/2) + imgheight,
         
           AOI_topright_x_min = x_center + (scene_width/2) - imgwidth,
           AOI_topright_x_max = x_center + (scene_width/2),
           AOI_topright_y_min = y_center + (scene_height/2) - imgheight,
           AOI_topright_y_max = y_center + (scene_height/2),
         
           AOI_bottomright_x_min = x_center + (scene_width/2) - imgwidth,
           AOI_bottomright_x_max = x_center + (scene_width/2),
           AOI_bottomright_y_min = y_center - (scene_height/2),
           AOI_bottomright_y_max = y_center - (scene_height/2) + imgheight,
         
           AOI_center_x_min = x_center - (center_imgwidth/2),
           AOI_center_x_max = x_center + (center_imgwidth/2),
           AOI_center_y_min = y_center - (center_imgheight/2),
           AOI_center_y_max = y_center + (center_imgheight/2)) %>%
  
  mutate(look = case_when(x<AOI_topleft_x_max & x>AOI_topleft_x_min & y<AOI_topleft_y_max & y>AOI_topleft_y_min ~ "topleft",
                          x<AOI_bottomleft_x_max & x>AOI_bottomleft_x_min & y<AOI_bottomleft_y_max & y > AOI_bottomleft_y_min ~ "bottomleft",
                          x<AOI_topright_x_max & x>AOI_topright_x_min & y<AOI_topright_y_max & y>AOI_topright_y_min ~ "topright",
                          x<AOI_bottomright_x_max & x>AOI_bottomright_x_min & y<AOI_bottomright_y_max & y>AOI_bottomright_y_min ~ "bottomright",
                          x<AOI_center_x_max & x>AOI_center_x_min & y<AOI_center_y_max & y>AOI_center_y_min ~ "center",
                         TRUE ~ "other")) %>%
  mutate(ROI = case_when(look==target_location ~ "target",
                         look==competitor_location ~ "competitor",
                         look=="center" ~ "center",
                         TRUE ~ "other")) %>%
  mutate(target_look = ifelse(ROI == "target", 1, 0), competitor_look = ifelse(ROI == "competitor", 1, 0), center_look = ifelse(ROI == "center", 1, 0), other_look = ifelse(ROI == "other", 1, 0)) %>%
  filter(look!="other") #TODO: remove other looks outside window?

# sanity check that ROIs are getting correctly assigned
ggplot(dd, aes(x=x,y=y,color=look)) +
  geom_point() +
  facet_wrap(~workerid,scales="free")
```

Bin samples and align time to the onset of words.
```{r,message=F,warning=F}
# relevant time columns------------
# trial_start: unix time at the beginning of the trial (when images are displayed)
# audio_play_unix: unix time at the beginning of the audio (after 1sec display preview)
# webgazer_time: elapsed time since webgazer started
# unix_tlist: unix time of each webgazer_time sample
# unix_rt: unix time of selection
# response_time: response time in ms (trial_start - unix_rt)

first_samples = dd %>% 
  group_by(workerid,slide_number) %>% 
  summarize(first_sample = min(webgazer_time))

# total number of samples:
nrow(first_samples)

# set size of time bins to collapse over
binsize = 60

# TODO: FIX EVERYTHING AFTER THIS --- 
# bin samples and align to target word onset
dd_binned = dd %>% 
  left_join(first_samples,by=c("workerid","slide_number")) %>% 
  mutate(relative_time = webgazer_time-first_sample) %>% 
  mutate(relative_time_bin=floor(relative_time/binsize)) %>% 
  mutate(binned_time_relative = relative_time_bin*binsize)
```

Plot proportions of looks to all regions (target, competitor, center, other)
```{r message=F, warning=F}
# aggregate looks (compute proportions of looks to each region in each time bin and condition; add 95% bootstrapped confidence intervals)
agr = dd_binned %>% 
  group_by(condition,binned_time_relative) %>% 
  summarize(target_prop=mean(target_look),target_CILow=ci.low(target_look),target_CIHigh=ci.high(target_look),competitor_prop=mean(competitor_look),competitor_CILow=ci.low(competitor_look),competitor_CIHigh=ci.high(competitor_look),center_prop=mean(center_look),center_CILow=ci.low(center_look),center_CIHigh=ci.high(center_look),other_prop=mean(other_look),other_CILow=ci.low(other_look),other_CIHigh=ci.high(other_look)) %>% 
  ungroup() %>% 
  mutate(target_ymin=target_prop-target_CILow,target_ymax=target_prop+target_CIHigh,competitor_ymin=competitor_prop-competitor_CILow,competitor_ymax=competitor_prop+competitor_CIHigh,center_ymin=center_prop-center_CILow,center_ymax=center_prop+center_CIHigh,other_ymin=other_prop-other_CILow,other_ymax=other_prop+other_CIHigh)

# prepare data for plotting
long_props = agr %>% 
  select(condition,binned_time_relative,target_prop,competitor_prop,center_prop,other_prop) %>% 
  pivot_longer(cols = target_prop:other_prop,names_to=c("region"),values_to=c("proportion")) %>% 
  separate(region,c("region",NA))

long_ymin = agr %>% 
  select(condition,binned_time_relative,target_ymin,competitor_ymin,center_ymin,other_ymin) %>% 
  pivot_longer(cols = target_ymin:other_ymin,names_to=c("region"),values_to=c("ymin")) %>% 
  separate(region,c("region",NA))

long_ymax = agr %>% 
  select(condition,binned_time_relative,target_ymax,competitor_ymax,center_ymax,other_ymax) %>% 
  pivot_longer(cols = target_ymax:other_ymax,names_to=c("region"),values_to=c("ymax")) %>% 
  separate(region,c("region",NA))

toplot = long_props %>% 
  left_join(long_ymin,by=c("condition","binned_time_relative","region")) %>% 
  left_join(long_ymax,by=c("condition","binned_time_relative","region")) %>% 
  mutate(region = fct_relevel(region,"target","competitor","center"))
```

```{r fig1,  fig.height=8, fig.width=6}
ggplot(toplot, aes(x=binned_time_relative,y=proportion)) +
  geom_line(size=1, aes(color=region)) +
  geom_ribbon(aes(ymin=ymin,ymax=ymax,fill=region),alpha=.3) +
  scale_color_manual(values=cbPalette[2:5]) +
  scale_fill_manual(values=cbPalette[2:5]) +
  geom_vline(aes(xintercept=200),linetype="dashed",size=1) +
  #geom_vline(data=durations,aes(xintercept=mean_audio_offset+200),linetype="dashed",size=1) +
  xlab("Time in ms relative to target word onset") +
  ylab("Proportion of looks") +
  #geom_text(data=annotations,aes(label=Label)) +
  facet_wrap(~condition,nrow=3)
```